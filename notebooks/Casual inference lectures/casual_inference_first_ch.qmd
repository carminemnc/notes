---
title: "On Casual Inference"
author: "Carmine Minichini"
description: "Unscrambling the chicken and the egg"
date: "2024-10-28"
categories: [casual inference, R]
image: mickey_mouse.gif
---

```{r, include = FALSE}
library(ggplot2)
library(latex2exp)
library(rstudioapi)
options(warn=-1)
```

## Background

![](https://www.vanderschaar-lab.com/wp-content/uploads/2020/12/CausInf.jpg)

La causal inference è fondamentale per comprendere e quantificare gli effetti di interventi, trattamenti o politiche su una popolazione di interesse. A differenza dell'analisi della semplice associazione tra variabili, la **causal inference** mira a stabilire relazioni causali, ovvero a identificare l'effetto di una variabile (il trattamento) sulla variabile di interesse (l'outcome), tenendo conto dei **fattori confondenti**.

## 1. Notazione

Sia $(\mathbf{X}_i, W_i, Y_i)$ per l'individuo $i$, dove:

-   $\mathbf{X}_i$ è il vettore di covariate osservate per l'individuo $i$
-   $W_i \in \{0, 1\}$ indica l'assegnazione al trattamento (0 = controllo, 1 = trattamento)
-   $Y_i$ è l'outcome osservato

Assumiamo che i dati siano generati in modo indipendente e i.i.d. (identicamente distribuito).

Introduciamo i concetti di *potenziali outcomes*:

-   $Y_i(1)$ è l'outcome potenziale dell'individuo $i$ se fosse stato assegnato al trattamento
-   $Y_i(0)$ è l'outcome potenziale dell'individuo $i$ se fosse stato assegnato al controllo

Quindi l'outcome osservato $Y_i$ corrisponde a uno dei due potenziali outcomes:

$$ Y_i \equiv Y_i(W_i) = \begin{cases} Y_i(1) & \text{se } W_i = 1 \\ Y_i(0) & \text{se } W_i = 0 \end{cases} $$

### Il nostro obiettivo

L'obiettivo è stimare l'effetto medio del trattamento (ATE):

$$ \tau = \mathbb{E}[Y_i(1) - Y_i(0)] $$

-   L'ATE fornisce una misura complessiva dell'impatto di un trattamento sulla popolazione target.

-   Stimare l'ATE è il primo passo per studiare i meccanismi attraverso cui un trattamento influenza gli outcome.

La stima dell'ATE è cruciale per valutare l'impatto di interventi, supportare le decisioni di policy, comprendere i meccanismi causali e progettare future ricerche empiriche in modo efficace. È un passaggio fondamentale nell'analisi causale.

#### In un contesto sperimentale...

In un contesto sperimentale, l'assegnazione al trattamento è indipendente dai potenziali outcomes:

$$ Y_i(1), Y_i(0) \perp W_i $$

In altre parole, non ci sono variabili confondenti che influenzano sia l'assegnazione al trattamento che l'outcome.

```{r}
# Read in data
data <- read.csv("welfare-small.csv")

ggplot(data,
       aes(x= age +rnorm(n=sum(W=w),sd=.1),
           y=polviews+rnorm(n=sum(W=w),sd=.1))) + 
  geom_point(size=2,color='#0085A1',alpha=0.3) + 
  facet_wrap(
    vars(ifelse(w,'Controllo','Trattamento'))
  ) +
  labs(title="Distribuzione dell'outcome in un contesto sperimentale",
       subtitle = TeX('$Y_i(1), Y_i(0) \\perp W_i$'),
       x="Age",
       y="Polviews") +
  theme(
    # Set black background
    plot.background = element_rect(fill = "#242728"),
    panel.background = element_rect(fill = "#242728"),
    
    # Set white text for all elements
    text = element_text(color = "#eaeaea"),
    axis.text = element_text(color = "#eaeaea"),
    axis.title = element_text(color = "#eaeaea"),
    title = element_text(face='italic',size=13),
    
    # Set green facet wrap labels
    strip.background = element_rect(fill = "#0085A1"),
    strip.text = element_text(color = "#eaeaea", face = "bold",size = 12),
    
    # Optional: adjust grid lines for better visibility
    panel.grid.major = element_line(color = "grey30"),
    panel.grid.minor = element_line(color = "grey20"),
    
    # Optional: set legend theme to match
    legend.background = element_rect(fill = "#242728"),
    legend.text = element_text(color = "#eaeaea"),
    legend.title = element_text(color = "#eaeaea"),
  )
```

#### In un contesto reale...

```{r}
# defining the group that will be dropped with some high probability
grp <- ((data$w == 1) &  # if treated AND...
        (
            (data$age > 45) |     # belongs an older group OR
            (data$polviews < 5)   # more conservative
        )) | # OR
        ((data$w == 0) &  # if untreated AND...
        (
            (data$age < 45) |     # belongs a younger group OR
            (data$polviews > 4)   # more liberal
        )) 

# Individuals in the group above have a smaller chance of being kept in the sample
prob.keep <- ifelse(grp, .15, .85)
keep.idx <- as.logical(rbinom(n=nrow(data), prob=prob.keep, size = 1))

# Dropping
data <- data[keep.idx,]

ggplot(data,
       aes(x= age +rnorm(n=sum(W=w),sd=.1),
           y=polviews+rnorm(n=sum(W=w),sd=.1))) + 
  geom_point(size=2,color='#0085A1',alpha=0.3) + 
  facet_wrap(
    vars(ifelse(w,'Controllo','Trattamento'))
  ) +
  labs(title="Distribuzione dell'outcome in un contesto reale",
       x="Age",
       y="Polviews") +
  theme(
    # Set black background
    plot.background = element_rect(fill = "#242728"),
    panel.background = element_rect(fill = "#242728"),
    
    # Set white text for all elements
    text = element_text(color = "#eaeaea"),
    axis.text = element_text(color = "#eaeaea"),
    axis.title = element_text(color = "#eaeaea"),
    title = element_text(face='italic',size=13),
    
    # Set green facet wrap labels
    strip.background = element_rect(fill = "#0085A1"),
    strip.text = element_text(color = "#eaeaea", face = "bold",size = 12),
    
    # Optional: adjust grid lines for better visibility
    panel.grid.major = element_line(color = "grey30"),
    panel.grid.minor = element_line(color = "grey20"),
    
    # Optional: set legend theme to match
    legend.background = element_rect(fill = "#242728"),
    legend.text = element_text(color = "#eaeaea"),
    legend.title = element_text(color = "#eaeaea")
  )
```

In un contesto reale o osservazionale dobbiamo fare delle assunzioni molto forti per poter stimare l'effetto medio del trattamento.

1.  **Ipotesi di confondimento (unconfoundedness):**
    -   Questa ipotesi afferma che, una volta condizionato sulle covariate osservate $X_i$, l'assegnazione al trattamento $W_i$ è indipendente dai potenziali outcomes $Y_i(1)$ e $Y_i(0)$.
    -   In altre parole, tutte le possibili fonti di selezione nel trattamento possono essere spiegate dalle covariate osservate.
    -   Matematicamente: $Y_i(1), Y_i(0) \perp W_i | X_i$
    -   Questa ipotesi permette di identificare l'effetto causale del trattamento, altrimenti non osservabile.
2.  **Ipotesi di sovrapposizione (overlap):**
    -   Questa ipotesi afferma che per ogni possibile combinazione di valori delle covariate $X_i$, esiste una probabilità positiva di essere assegnati sia al trattamento che al controllo.
    -   In altre parole, non ci devono essere regioni del supporto delle covariate in cui tutti gli individui sono sempre trattati o sempre di controllo.
    -   Matematicamente: $\eta < e(x) < 1 - \eta$ per qualche $\eta > 0$ e per tutti i $x$, dove $e(x) = \mathbb{P}[W_i = 1 | X_i = x]$ è la propensione al trattamento.
    -   Questa ipotesi garantisce che sia possibile confrontare unità trattate e di controllo con caratteristiche simili.

Insieme, queste due ipotesi permettono di identificare l'effetto causale del trattamento nell'ambito di un contesto osservazionale. L'ipotesi di confondimento assicura che non ci siano variabili non osservate che influenzano sia l'assegnazione al trattamento che l'outcome. L'ipotesi di sovrapposizione garantisce che ci siano unità di confronto appropriate per ogni individuo trattato.

Queste ipotesi sono cruciali per l'applicabilità di metodi come l'IPW e l'AIPW, discussi nelle sezioni successive.

## 2. Difference in means

Lo stimatore della differenza delle medie (difference-in-means) è un semplice stimatore non distorto dell'ATE. L'idea è calcolare la media dei outcomes nel gruppo di trattamento meno la media dei outcomes nel gruppo di controllo:

$$
\hat{\tau}_\text{DIFF} = \frac{1}{n_1} \sum_{i: W_i = 1} Y_i - \frac{1}{n_0} \sum_{i: W_i = 0} Y_i
$$

dove $n_w = |\{i: W_i = w\}|$ è il numero di individui nel gruppo $w$.

Lo stimatore della differenza delle medie può essere utilizzato solamente nel contesto sperimentale, ovvero quando l'assegnazione al trattamento è casuale e indipendente dai potenziali outcomes.

In questo caso, l'ipotesi di indipendenza tra assegnazione al trattamento e potenziali outcomes cioè l'ipotesi che $Y_i(1), Y_i(0) \perp W_i$ è soddisfatta.

Ciò significa che non ci sono fattori confondenti che influenzano sia l'assegnazione al trattamento che l'outcome.

Sotto questa ipotesi, la differenza tra la media dei outcomes nel gruppo di trattamento e la media dei outcomes nel gruppo di controllo fornisce una stima non distorta dell'effetto medio del trattamento (ATE).

In contesti osservazionali, invece, sono necessari metodi più avanzati come l'IPW e l'AIPW.

## 3. Direct estimator

Lo stimatore diretto (direct estimation) è un metodo per stimare l'effetto medio del trattamento (ATE) che può essere utilizzato in contesti osservazionali, ovvero quando l'assegnazione al trattamento non è casuale ma dipende dalle covariate osservate $X_i$.

Questo stimatore sfrutta la seguente scomposizione:

$\mathbb{E}[Y_i(1) - Y_i(0)] = \mathbb{E}[\mathbb{E}[Y_i|X_i, W_i=1]] - \mathbb{E}[\mathbb{E}[Y_i|X_i, W_i=0]]$

La procedura per applicare lo stimatore diretto è la seguente:

1.  Stimare $\mu(x, w) = \mathbb{E}[Y_i|X_i=x, W_i=w]$ utilizzando metodi di regressione non parametrici.
2.  Predire $\hat{\mu}(X_i, 1)$ e $\hat{\mu}(X_i, 0)$ per ogni osservazione.
3.  Calcolare la media delle differenze predette:

$\hat{\tau}_\text{DM} = \frac{1}{n} \sum_{i=1}^n \left[\hat{\mu}(X_i, 1) - \hat{\mu}(X_i, 0)\right]$

Questo stimatore sfrutta la regressione per ottenere stime più accurate dell'ATE rispetto al semplice difference-in-means visto precedentemente.

**Quando usarlo**: Lo stimatore diretto può essere utilizzato nel contesto osservazionale, quando l'ipotesi di confondimento ($Y_i(1), Y_i(0) \perp W_i | X_i$) è soddisfatta. Ciò significa che tutte le variabili confondenti sono state misurate e incluse nelle covariate $X_i$.

**Quando non usarlo**: Lo stimatore diretto ha alcuni svantaggi: - Dipende fortemente dalla corretta specificazione del modello per $\mu(x, w)$. Se il modello è mal specificato, le stime saranno distorte. - Non gode delle stesse proprietà asintotiche (come l'efficienza) degli stimatori più avanzati come l'AIPW.

Pertanto, quando possibile, è preferibile utilizzare metodi come l'AIPW, che sono più robusti alle ipotesi di modellazione.

## 4. IPW (Inverse propensity-weighted estimator)

L'estimatore inverse propensity-weighted (IPW) è un metodo per stimare l'effetto medio del trattamento (ATE) che può essere utilizzato in contesti osservazionali, ovvero quando l'assegnazione al trattamento non è casuale ma dipende dalle covariate $X_i$.

L'idea chiave dell'IPW è di utilizzare i pesi inversi della propensione al trattamento per "bilanciare" il confronto tra individui trattati e di controllo.

La procedura per applicare l'IPW è la seguente:

1.  Stimare la propensione al trattamento $e(X_i) = \mathbb{P}[W_i = 1 | X_i]$ utilizzando un modello di regressione (ad esempio, logistica).
2.  Calcolare i pesi inversamente proporzionali alla propensione stimata:
    -   Per gli individui trattati: $W_i / \hat{e}(X_i)$
    -   Per gli individui di controllo: $(1 - W_i) / (1 - \hat{e}(X_i))$
3.  Calcolare la media ponderata dei outcomes:

$\hat{\tau}_\text{IPW} = \frac{1}{n} \sum_{i=1}^n \left[ \frac{W_i \, Y_i}{\hat{e}(X_i)} - \frac{(1 - W_i) \, Y_i}{1 - \hat{e}(X_i)} \right]$

**Quando usarlo**: L'IPW può essere utilizzato nel contesto osservazionale, quando sono soddisfatte le ipotesi di confondimento ($Y_i(1), Y_i(0) \perp W_i | X_i$) e di sovrapposizione ($\eta < e(x) < 1 - \eta$ per qualche $\eta > 0$).

**Vantaggi dell'IPW**: - È un metodo semplice da implementare. - È robusto: se il modello per la propensione è correttamente specificato, l'IPW fornisce stime non distorte dell'ATE.

**Svantaggi dell'IPW**: - Quando la propensione al trattamento è molto piccola, i pesi diventano molto grandi, rendendo lo stimatore instabile e con alta varianza. - L'IPW non sfrutta appieno l'informazione contenuta nelle covariate per migliorare l'efficienza della stima.

Per superare questi svantaggi, nella prossima sezione verrà introdotto un metodo più sofisticato, l'AIPW, che combina i vantaggi dell'IPW e della regressione diretta.

## 5. AIPW (Augmented inverse propensity-weighted estimator)

L'estimatore AIPW è disponibile in contesti con ipotesi di non confondimento e overlapping. La sua formula è la seguente:

$$\hat{\tau}_\mathrm{AIPW} := \frac{1}{n} \sum_{i=1}^n \left(\hat{\mu}_{-i}(X_i, 1) - \hat{\mu}_{-i}(X_i, 0)\right) + \frac{W_i}{\hat{e}_{-i}(X_i)} (Y_i - \hat{\mu}_{-i}(X_i, 1)) - \frac{1-W_i}{1-\hat{e}_{-i}(X_i)} (Y_i - \hat{\mu}_{-i}(X_i, 0))$$

Vantaggi dell'estimatore AIPW:

1.  **Doppia robustezza**: l'estimatore è corretto se almeno uno tra il modello di outcome $\hat{\mu}(X_i, w)$ o il modello di propensity score $\hat{e}(X_i)$ è corretto.
2.  **Efficienza**: sotto ipotesi deboli, l'AIPW è asintoticamente efficiente, ovvero ha la minima varianza asintotica tra una classe ampia di stimatori.
3.  **Normalità asintotica**: l'AIPW è asintoticamente normale, permettendo un facile calcolo di errori standard e p-value.

Rispetto agli altri stimatori visti precedentemente:

-   È più efficiente del difference-in-means anche in contesti sperimentali.
-   È più robusto del direct estimator e dell'IPW quando i modelli sono mal specificati.

Svantaggi:

-   Richiede la stima di due modelli (outcome e propensity score), il che può essere impegnativo in pratica.
-   Quando i propensity score sono molto vicini a 0 o 1, l'AIPW può avere prestazioni instabili. In tal caso, altri stimatori come l'approximate residual balancing (ARB) possono essere preferibili.

In sintesi, l'AIPW è uno stimatore raccomandato in contesti osservazionali con ipotesi di non confondimento e overlapping, grazie alla sua doppia robustezza e efficienza asintotica. La sua implementazione può però risultare più complessa rispetto ad altri stimatori.
